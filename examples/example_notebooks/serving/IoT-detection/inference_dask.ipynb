{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fa0d2e4",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "566b45cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install mxnet==1.8.0 --quiet\n",
    "!pip install autogluon.tabular --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e0e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f305421a",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658ffa2f",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "## parameter cell\n",
    "data_path = \"s3://shakdemo-aws/data/iot/iot_telemetry_data.csv\"\n",
    "label = 'motion'\n",
    "device = \"001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c53c9113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405184, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "data_nolab = data.drop(columns=[label, 'device'])\n",
    "data_inference = pd.concat([data_nolab]*1)\n",
    "data_inference.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02acde64",
   "metadata": {},
   "source": [
    "## Start a Dask cluster for fast distributed inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10bd01d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘‰ Hyperplane: selecting worker node pool\n",
      "ðŸ‘‰ Hyperplane: selecting scheduler node pool\n",
      "Creating scheduler pod on cluster. This may take some time.\n",
      "ðŸ‘‰ Hyperplane: spinning up a dask cluster with a scheduler as a standalone container.\n",
      "ðŸ‘‰ Hyperplane: In a few minutes you'll be able to access the dashboard at https://shakdemo2.hyperplane.dev/dask-cluster-8633cfe2-b58a-4d0c-9a8e-96a25201659c/status\n",
      "ðŸ‘‰ Hyperplane: to get logs from all workers, do `cluster.get_logs()`\n",
      "spinning up 1 110 G workers nprocs = 15 nthreads = 1 ram_per_proc = 7.333333333333333 G\n"
     ]
    }
   ],
   "source": [
    "import hyperplane.notebook_common as nc\n",
    "\n",
    "\n",
    "## choose number of proces and processes\n",
    "num_workers = 1\n",
    "nprocs = 15\n",
    "\n",
    "## node size\n",
    "cors_per_worker = 15\n",
    "total_memory = 110\n",
    "\n",
    "\n",
    "ram_gb_per_proc = total_memory/nprocs\n",
    "nthreads = int(cors_per_worker/nprocs)\n",
    "\n",
    "\n",
    "client, cluster = nc.initialize_cluster(\n",
    "        nprocs = nprocs,\n",
    "        nthreads = int(cors_per_worker/nprocs),\n",
    "        ram_gb_per_proc = total_memory/nprocs,\n",
    "        cores_per_worker = cors_per_worker,\n",
    "        num_workers = num_workers,\n",
    "        node_selector = {}\n",
    "    )\n",
    "\n",
    "print(f'spinning up {num_workers} {total_memory} G workers nprocs = {nprocs} nthreads = {nthreads} ram_per_proc = {ram_gb_per_proc} G')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80615d68",
   "metadata": {},
   "source": [
    "<a href=\"#results\">Go to Results</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e07ffea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 339 ms, sys: 78.6 ms, total: 418 ms\n",
      "Wall time: 6min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tcp://10.0.178.172:33463': {'status': 'OK'},\n",
       " 'tcp://10.0.178.172:35079': {'status': 'OK'},\n",
       " 'tcp://10.0.178.172:35351': {'status': 'OK'},\n",
       " 'tcp://10.0.178.172:35411': {'status': 'OK'},\n",
       " 'tcp://10.0.178.172:36197': {'status': 'OK'},\n",
       " 'tcp://10.0.178.172:38159': {'status': 'OK'},\n",
       " 'tcp://10.0.178.172:38277': {'status': 'OK'},\n",
       " 'tcp://10.0.178.172:41825': {'status': 'OK'},\n",
       " 'tcp://10.0.178.172:43091': {'status': 'OK'},\n",
       " 'tcp://10.0.178.172:43215': {'status': 'OK'},\n",
       " 'tcp://10.0.178.172:43775': {'status': 'OK'},\n",
       " 'tcp://10.0.178.172:44483': {'status': 'OK'},\n",
       " 'tcp://10.0.178.172:46523': {'status': 'OK'},\n",
       " 'tcp://10.0.178.172:46685': {'status': 'OK'},\n",
       " 'tcp://10.0.178.172:46765': {'status': 'OK'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from dask.distributed import PipInstall\n",
    "plugin = PipInstall(packages=[\"mxnet==1.8.0\",\"autogluon\"])\n",
    "client.register_worker_plugin(plugin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed216432",
   "metadata": {},
   "source": [
    "## download the trained model to workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8baee4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_cloud(local_file_name, remote_file_name):\n",
    "    \"\"\"\n",
    "    Download a file to gcp or s3.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import s3fs\n",
    "    import gcsfs\n",
    "    cloud_name = remote_file_name.split('://')[0]\n",
    "    if cloud_name =='gs':\n",
    "        fs = gcsfs.GCSFileSystem(project=os.environ['GCP_PROJECT'])\n",
    "    elif cloud_name =='s3':\n",
    "        fs = s3fs.S3FileSystem()\n",
    "    else:\n",
    "        raise NameError(f'cloud name {cloud_name} unknown')\n",
    "    try:    \n",
    "        print(f'downloading from {remote_file_name} to {local_file_name}...')\n",
    "        fs.get(remote_file_name, local_file_name, recursive=True)\n",
    "        print(\"done downloading!\")\n",
    "    except Exception as exp:\n",
    "        print(f\"download failed: {exp}\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed3eafb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model():\n",
    "    local_file_path = 'models'\n",
    "    remote_file_path =f\"s3://shakdemo-aws/demo/iot/{local_file_path}\"\n",
    "    download_from_cloud(local_file_path, remote_file_path)\n",
    "    return 'success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77ea66a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.7 ms, sys: 747 Âµs, total: 3.45 ms\n",
      "Wall time: 1.26 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tcp://10.0.178.172:33463': 'success',\n",
       " 'tcp://10.0.178.172:35079': 'success',\n",
       " 'tcp://10.0.178.172:35351': 'success',\n",
       " 'tcp://10.0.178.172:35411': 'success',\n",
       " 'tcp://10.0.178.172:36197': 'success',\n",
       " 'tcp://10.0.178.172:38159': 'success',\n",
       " 'tcp://10.0.178.172:38277': 'success',\n",
       " 'tcp://10.0.178.172:41825': 'success',\n",
       " 'tcp://10.0.178.172:43091': 'success',\n",
       " 'tcp://10.0.178.172:43215': 'success',\n",
       " 'tcp://10.0.178.172:43775': 'success',\n",
       " 'tcp://10.0.178.172:44483': 'success',\n",
       " 'tcp://10.0.178.172:46523': 'success',\n",
       " 'tcp://10.0.178.172:46685': 'success',\n",
       " 'tcp://10.0.178.172:46765': 'success'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "client.run(download_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d2d13b",
   "metadata": {},
   "source": [
    "## Read data onto the dask workers and do distributed inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2728ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import dataframe as dd\n",
    "df = dd.from_pandas(data_inference, npartitions= len(client.has_what()))\n",
    "print(len(df), df.npartitions)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c32f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_function(df: pd.DataFrame, model_path) ->pd.DataFrame:\n",
    "    from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "    data = TabularDataset(df)\n",
    "    predictor = TabularPredictor.load(model_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "    y_pred = predictor.predict(df)\n",
    "    df['pred'] = y_pred.values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542cfd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dtype\n",
    "meta = {\n",
    "    'ts': dtype('float64'),\n",
    "    'co': dtype('float64'),\n",
    "    'humidity': dtype('float64'),\n",
    "    'light': dtype('bool'),\n",
    "    'lpg': dtype('float64'),\n",
    "    'smoke': dtype('float64'),\n",
    "    'temp': dtype('float64'),\n",
    "    'pred': dtype('bool')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd288dcb",
   "metadata": {},
   "source": [
    "<a id='results'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81bec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df.map_partitions(inference_function, model_path = '/root/models/', meta= meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93519e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_pred_local = df_pred.compute()\n",
    "print(df_pred_local.shape)\n",
    "df_pred_local.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4802569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51d56cb",
   "metadata": {},
   "source": [
    "## inference in pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "starttime = time.time()\n",
    "df_pred_local_pandas = inference_function(data_inference, model_path= './models/')\n",
    "print(f'finished in {time.time() - starttime} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2287497a",
   "metadata": {},
   "source": [
    "With distributed dask nodes, the inference is done with **2 Dask nodes** in parallel, which took about **28 seconds** in total. That's **over 2x speed up** compared to pandas and an ability to handle data **larger than memory**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
