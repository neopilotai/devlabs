{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb0bea8b",
   "metadata": {},
   "source": [
    "## Use Ray Tune and MLFlow on Hyperplane "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorboardX --quiet\n",
    "# !pip install kubernetes==18.20 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b624a2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 05:29:55.971324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ray version 1.8.0\n",
      "tf version 2.4.1\n",
      "torch version 1.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import tensorflow as tf\n",
    "import torch \n",
    "print(f'ray version {ray.__version__}')\n",
    "print(f'tf version {tf.__version__}')\n",
    "print(f'torch version {torch.__version__}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa2d67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘‰ Hyperplane: selecting worker node pool\n",
      "best pool spec {'pool_env_var': 'DASK_POOL_16_16', 'allocatable_cores': 15.0, 'allocatable_ram': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 05:30:05,885\tWARNING services.py:1748 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=8.39gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for worker ray-worker-d41fba09-79e7-47c2-8da7-0a75d0eab126...\n",
      "Waiting for worker ray-worker-24b53498-d460-42f6-a1a7-ade2d34dc1e9...\n"
     ]
    }
   ],
   "source": [
    "from hyperplane.ray_common import initialize_ray_cluster, stop_ray_cluster, find_ray_workers\n",
    "num_workers = 2\n",
    "cpu_core_per_worker = 7\n",
    "ram_gb_per_worker = 6 #110 GB allocatible for 16_128 nodes, 12 for 16_16 nodes, 27 for 32_32 nodes\n",
    "ray_cluster = initialize_ray_cluster(num_workers, cpu_core_per_worker, ram_gb_per_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab1c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet, ip=10.1.155.4)\u001b[0m [2021-12-08 05:30:09,168 E 17 17] agent_manager.cc:134: Not all required Ray dependencies for the runtime_env feature were found. To install the required dependencies, please run `pip install 'ray[default]'`.\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.1.155.4)\u001b[0m [2021-12-08 05:30:09,168 E 17 17] worker_pool.cc:566: [Eagerly] Couldn't create a runtime environment for job 01000000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow version 1.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet, ip=10.1.156.4)\u001b[0m [2021-12-08 05:30:09,377 E 16 16] agent_manager.cc:134: Not all required Ray dependencies for the runtime_env feature were found. To install the required dependencies, please run `pip install 'ray[default]'`.\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.1.156.4)\u001b[0m [2021-12-08 05:30:09,377 E 16 16] worker_pool.cc:566: [Eagerly] Couldn't create a runtime environment for job 01000000.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.integration.mlflow import MLflowLoggerCallback, mlflow_mixin\n",
    "print('mlflow version', mlflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_fn(step, width, height):\n",
    "    return (0.1 + width * step / 100)**(-1) + height * 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8bd767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_objective(config):\n",
    "    # Hyperparameters\n",
    "    width, height = config[\"width\"], config[\"height\"]\n",
    "\n",
    "    for step in range(config.get(\"steps\", 100)):\n",
    "        # Iterative training function - can be any arbitrary training procedure\n",
    "        intermediate_score = evaluation_fn(step, width, height)\n",
    "        # Feed the score back to Tune.\n",
    "        tune.report(iterations=step, mean_loss=intermediate_score)\n",
    "        time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66b2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_function(mlflow_tracking_uri, finish_fast=False):\n",
    "    tune.run(\n",
    "        easy_objective,\n",
    "        name=\"mlflow\",\n",
    "        num_samples=5,\n",
    "        callbacks=[\n",
    "            MLflowLoggerCallback(\n",
    "                tracking_uri=mlflow_tracking_uri,\n",
    "                experiment_name=\"mixin_example\",\n",
    "                save_artifact=True)\n",
    "        ],\n",
    "        config={\n",
    "            \"width\": tune.randint(10, 100),\n",
    "            \"height\": tune.randint(0, 100),\n",
    "            \"steps\": 5 if finish_fast else 100,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "@mlflow_mixin\n",
    "def decorated_easy_objective(config):\n",
    "    # Hyperparameters\n",
    "    width, height = config[\"width\"], config[\"height\"]\n",
    "\n",
    "    for step in range(config.get(\"steps\", 100)):\n",
    "        # Iterative training function - can be any arbitrary training procedure\n",
    "        intermediate_score = evaluation_fn(step, width, height)\n",
    "        # Log the metrics to mlflow\n",
    "        mlflow.log_metrics(dict(mean_loss=intermediate_score), step=step)\n",
    "        # Feed the score back to Tune.\n",
    "        tune.report(iterations=step, mean_loss=intermediate_score)\n",
    "        time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e7e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_decorated(mlflow_tracking_uri, finish_fast=False):\n",
    "    # Set the experiment, or create a new one if does not exist yet.\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "    mlflow.set_experiment(experiment_name=\"mixin_example\")\n",
    "    tune.run(\n",
    "        decorated_easy_objective,\n",
    "        name=\"mlflow\",\n",
    "        verbose = 1, \n",
    "        num_samples=5,\n",
    "        config={\n",
    "            \"width\": tune.randint(10, 100),\n",
    "            \"height\": tune.randint(0, 100),\n",
    "            \"steps\": 5 if finish_fast else 100,\n",
    "            \"mlflow\": {\n",
    "                \"experiment_name\": \"mixin_example\",\n",
    "                \"tracking_uri\": mlflow.get_tracking_uri()\n",
    "            }\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49479f22",
   "metadata": {},
   "source": [
    "## setup MLFlow tracking URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0910af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://postgres:postgres@postgresql.postgres-m288j5y2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "mlflow.set_tracking_uri(os.environ.get('DATABASE_URL_NO_PARAMS')[:-12]) ## this one \n",
    "tracking_uri = mlflow.get_tracking_uri()\n",
    "print(tracking_uri)\n",
    "\n",
    "experiment_name = 'pbt_babi_memnn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dcba6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-08 05:36:35 (running for 00:00:18.28)<br>Memory usage on this node: 2.4/31.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/37 CPUs, 0/0 GPUs, 0.0/32.0 GiB heap, 0.0/14.8 GiB objects<br>Result logdir: /root/ray_results/mlflow<br>Number of trials: 5/5 (5 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 05:36:35,856\tINFO tune.py:630 -- Total run time: 18.43 seconds (18.26 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "tune_decorated(tracking_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1457fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting ray-worker-d41fba09-79e7-47c2-8da7-0a75d0eab126\n",
      "Deleting ray-worker-24b53498-d460-42f6-a1a7-ade2d34dc1e9\n"
     ]
    }
   ],
   "source": [
    "stop_ray_cluster(ray_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f23b80-f277-4c60-a2bc-443a38611e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
