{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248d39d3",
   "metadata": {},
   "source": [
    "## A boilerplate code for using Dask to read from Snowflake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0657a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "df = dd.read_sql_table(\n",
    "    'accounts', \n",
    "    'snowflake://user:pass@...warehouse=...role=...', \n",
    "    npartitions=10, \n",
    "    index_col='id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063437a0-0743-424c-867f-9f9fed346e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please checkout the API documentation https://yourdomain.hyperplane.dev/hyperplane_docs/api.html for more details\n",
    "\n",
    "from hyperplane import notebook_common as nc\n",
    "num_workers = 2  # number of nodes to spin up\n",
    "\n",
    "## node specific parameters\n",
    "total_memory = 110 #110 GB allocatible for 16_128 nodes, 12G for 16_16 nodes, 27G for 32_32\n",
    "cors_per_worker = 15   # 15 cores for 16_128 nodes and 16_16 nodes, 28 cores for 32_32 nodes\n",
    "nprocs = 15\n",
    "ram_gb_per_proc = total_memory/nprocs\n",
    "nthreads = int(cors_per_worker/nprocs)\n",
    "\n",
    "print(f'initializing with {num_workers} num_workers, {nprocs} nprocs each proc has {ram_gb_per_proc} GB')\n",
    "client, cluster = nc.initialize_cluster(\n",
    "        num_workers = num_workers,\n",
    "        nprocs = nprocs,\n",
    "        nthreads = nthreads,\n",
    "        ram_gb_per_proc = ram_gb_per_proc,\n",
    "        cores_per_worker = cors_per_worker\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490df05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "from dask.dataframe import from_delayed\n",
    "from dask.distributed import delayed\n",
    "\n",
    "@delayed\n",
    "def load(connection_info, query, start, end):\n",
    "    conn = snowflake.connector.connect(**connection_info)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query, start, end)\n",
    "    return cur.fetch_pandas_all()\n",
    "ddf = from_delayed(*[load(connection_info, query, st, ed) for st, ed in partitions])\n",
    "ddf.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b1394c-0157-4148-a978-a1a0a64a1047",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
