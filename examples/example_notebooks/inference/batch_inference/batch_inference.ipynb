{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f5e7c80",
   "metadata": {},
   "source": [
    "# Distributed batch_inference with dask \n",
    "- With Dask distributed, inference on 1000 rows finished in **1min 42s**\n",
    "- With Pandas non-distributed, inference on 5 rows took 2.69s, for 1000 rows the estimation is **8 min 46s**. \n",
    "- Dask achieves a **5.1 times speed up**, in line with the 6 workers in the Dask cluster. \n",
    "- To speed up more we can use more workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac2ff55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/root/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5813f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4804387b92fa4906b3110076dbaca5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2cbcc57ad1e455b9cf260ca089ff723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'activation_13', 'vocab_projector', 'vocab_layer_norm']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'classifier', 'dropout_19']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "pd.options.display.max_rows = 999\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import gcsfs\n",
    "import s3fs\n",
    "import pickle\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import activations, optimizers, losses\n",
    "from scheduler_setup import loaded_models\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ed7c8a",
   "metadata": {},
   "source": [
    "## Start a Dask cluster fror distributed inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1fe7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘‰ Hyperplane: selecting worker node pool\n",
      "ðŸ‘‰ Hyperplane: selecting scheduler node pool\n",
      "Creating scheduler pod on cluster. This may take some time.\n",
      "ðŸ‘‰ Hyperplane: spinning up a dask cluster with a scheduler as a standalone container.\n",
      "ðŸ‘‰ Hyperplane: In a few minutes you'll be able to access the dashboard at https://ds.hyperplane.dev/dask-cluster-c76da13e-b7fa-4d2f-a620-895721e9c986/status\n",
      "ðŸ‘‰ Hyperplane: to get logs from all workers, do `cluster.get_logs()`\n"
     ]
    }
   ],
   "source": [
    "from hyperplane import notebook_common as nc\n",
    "\n",
    "client, cluster = nc.initialize_cluster(\n",
    "    nprocs = 3,\n",
    "    nthreads = 5,\n",
    "    ram_gb_per_proc = 4,\n",
    "    cores_per_worker = 15,\n",
    "    num_workers = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b6250d",
   "metadata": {},
   "source": [
    "### install any necessary package on the cluster workers with dask worker plugin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd98698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.14 ms, sys: 2.34 ms, total: 11.5 ms\n",
      "Wall time: 8.55 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tcp://10.1.113.16:35955': {'status': 'OK'},\n",
       " 'tcp://10.1.113.16:37409': {'status': 'OK'},\n",
       " 'tcp://10.1.113.16:41277': {'status': 'OK'},\n",
       " 'tcp://10.1.114.16:35745': {'status': 'OK'},\n",
       " 'tcp://10.1.114.16:41753': {'status': 'OK'},\n",
       " 'tcp://10.1.114.16:45565': {'status': 'OK'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import PipInstall\n",
    "plugin = PipInstall(packages=[\"s3fs\"], pip_options=[\"--upgrade\"])\n",
    "client.register_worker_plugin(plugin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4a144",
   "metadata": {},
   "source": [
    "### Upload the scheduler_setup script, which loads the model to each dask worker for inference\n",
    "- this way the inference process does not need to download the model over and over during the inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d278ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tcp://10.1.113.16:35955': {'status': 'OK'},\n",
       " 'tcp://10.1.113.16:37409': {'status': 'OK'},\n",
       " 'tcp://10.1.113.16:41277': {'status': 'OK'},\n",
       " 'tcp://10.1.114.16:35745': {'status': 'OK'},\n",
       " 'tcp://10.1.114.16:41753': {'status': 'OK'},\n",
       " 'tcp://10.1.114.16:45565': {'status': 'OK'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upload_file('scheduler_setup.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5655af",
   "metadata": {},
   "source": [
    "### read parquet or csv file into Dask dataframe from your cloud bucket\n",
    "1. Download the data from [Kaggle](https://www.kaggle.com/yelp-dataset/yelp-dataset)\n",
    "2. Save it to your local or cloud location \n",
    "3. change the file path to where your data is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6769986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lWC-xP3rd6obsecCYsGZRg</td>\n",
       "      <td>ak0TdVmGKo4pwqdJSTLwWw</td>\n",
       "      <td>buF9druCkbuXLX526sGELQ</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Apparently Prides Osteria had a rough summer a...</td>\n",
       "      <td>1412998442000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8bFej1QE5LXp4O05qjGqXA</td>\n",
       "      <td>YoVfDbnISlW0f7abNQACIg</td>\n",
       "      <td>RA4V8pr014UyUbDvI-LW2A</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This store is pretty good. Not as great as Wal...</td>\n",
       "      <td>1435955905000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  lWC-xP3rd6obsecCYsGZRg  ak0TdVmGKo4pwqdJSTLwWw  buF9druCkbuXLX526sGELQ   \n",
       "1  8bFej1QE5LXp4O05qjGqXA  YoVfDbnISlW0f7abNQACIg  RA4V8pr014UyUbDvI-LW2A   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      4       3      1     1   \n",
       "1      4       1      0     0   \n",
       "\n",
       "                                                text                 date  \n",
       "0  Apparently Prides Osteria had a rough summer a...  1412998442000000000  \n",
       "1  This store is pretty good. Not as great as Wal...  1435955905000000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "file_path = \"gs://pipeline_data/ray_data/yelp_review_dask.parquet\"\n",
    "df = dd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72566ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id      object\n",
       "user_id        object\n",
       "business_id    object\n",
       "stars           int64\n",
       "useful          int64\n",
       "funny           int64\n",
       "cool            int64\n",
       "text           object\n",
       "date            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(df):\n",
    "    df['text'] = df.text.replace(r'\\r+|\\n+|\\t+','', regex=True)\n",
    "    df['text'] = df.text.str.lower()\n",
    "    return df\n",
    "\n",
    "df = df.map_partitions(clean_text)\n",
    "df['text'] = df.text.astype(str)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5655fc7",
   "metadata": {},
   "source": [
    "## Distributed inference with Dask\n",
    "- The most convenient way to run inference in dask is using the `map_partitions` function\n",
    "- The `predict` function is a normal function that do the inference on a pandas dataframe\n",
    "- Dask `map_partitions` function maps the `predict` function to each partition of the data dataframe, which are pandas dataframes (read more on [Dask dataframe](https://docs.dask.org/en/latest/dataframe.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c35d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df: pd.DataFrame, batch_size : str) -> pd.DataFrame:\n",
    "    import sys\n",
    "#     sys.path.append('/root')\n",
    "    from scheduler_setup import loaded_models\n",
    "    model, model_name, max_len = loaded_models['model']\n",
    "    \n",
    "    tkzr = DistilBertTokenizer.from_pretrained(model_name)\n",
    "    inputs = tkzr(df.text.tolist(),    \n",
    "                  padding='max_length',\n",
    "                  truncation=True, \n",
    "                  return_tensors='tf')\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((inputs['input_ids'],inputs['attention_mask']))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    import numpy as np\n",
    "    predictions = []\n",
    "    for i, (token_ids, masks) in enumerate(dataset):\n",
    "        pred = model(token_ids, attention_mask=masks)\n",
    "        labels = np.argmax(tf.nn.softmax(pred.logits, axis=0).numpy(), axis = 1)\n",
    "        predictions.append(labels)\n",
    "    predictions = np.hstack(predictions)\n",
    "    df['pred'] = predictions\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "410330b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 9)\n",
      "CPU times: user 9.07 s, sys: 1.82 s, total: 10.9 s\n",
      "Wall time: 2.69 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lWC-xP3rd6obsecCYsGZRg</td>\n",
       "      <td>ak0TdVmGKo4pwqdJSTLwWw</td>\n",
       "      <td>buF9druCkbuXLX526sGELQ</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>apparently prides osteria had a rough summer a...</td>\n",
       "      <td>1412998442000000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8bFej1QE5LXp4O05qjGqXA</td>\n",
       "      <td>YoVfDbnISlW0f7abNQACIg</td>\n",
       "      <td>RA4V8pr014UyUbDvI-LW2A</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>this store is pretty good. not as great as wal...</td>\n",
       "      <td>1435955905000000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDhkzczKjLshODbqDoNLSg</td>\n",
       "      <td>eC5evKn1TWDyHCyQAwguUw</td>\n",
       "      <td>_sS2LBIGNT5NQb6PD1Vtjw</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i called wvm on the recommendation of a couple...</td>\n",
       "      <td>1369773486000000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T5fAqjjFooT4V0OeZyuk1w</td>\n",
       "      <td>SFQ1jcnGguO0LYWnbbftAA</td>\n",
       "      <td>0AzLzHfOJgL7ROwhdww2ew</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>i've stayed at many marriott and renaissance m...</td>\n",
       "      <td>1262917755000000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sjm_uUcQVxab_EeLCqsYLg</td>\n",
       "      <td>0kA0PAJ8QFMeveQWHFqz2A</td>\n",
       "      <td>8zehGz9jnxPqXtOc7KaJxA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the food is always great here. the service fro...</td>\n",
       "      <td>1311876301000000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  lWC-xP3rd6obsecCYsGZRg  ak0TdVmGKo4pwqdJSTLwWw  buF9druCkbuXLX526sGELQ   \n",
       "1  8bFej1QE5LXp4O05qjGqXA  YoVfDbnISlW0f7abNQACIg  RA4V8pr014UyUbDvI-LW2A   \n",
       "2  NDhkzczKjLshODbqDoNLSg  eC5evKn1TWDyHCyQAwguUw  _sS2LBIGNT5NQb6PD1Vtjw   \n",
       "3  T5fAqjjFooT4V0OeZyuk1w  SFQ1jcnGguO0LYWnbbftAA  0AzLzHfOJgL7ROwhdww2ew   \n",
       "4  sjm_uUcQVxab_EeLCqsYLg  0kA0PAJ8QFMeveQWHFqz2A  8zehGz9jnxPqXtOc7KaJxA   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      4       3      1     1   \n",
       "1      4       1      0     0   \n",
       "2      5       0      0     0   \n",
       "3      2       1      1     1   \n",
       "4      4       0      0     0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  apparently prides osteria had a rough summer a...  1412998442000000000   \n",
       "1  this store is pretty good. not as great as wal...  1435955905000000000   \n",
       "2  i called wvm on the recommendation of a couple...  1369773486000000000   \n",
       "3  i've stayed at many marriott and renaissance m...  1262917755000000000   \n",
       "4  the food is always great here. the service fro...  1311876301000000000   \n",
       "\n",
       "   pred  \n",
       "0     0  \n",
       "1     1  \n",
       "2     1  \n",
       "3     0  \n",
       "4     1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Use Pandas\n",
    "df_local = df.head(5)\n",
    "print(df_local.shape)\n",
    "predict(df_local, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f84f5ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For the purpose of demo here, we sample only 1000 rows from the entire dataset\n",
    "print(len(df))\n",
    "df_sample = df.sample(0.001)\n",
    "len(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "314e2922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dtype\n",
    "meta = df.dtypes.to_dict()\n",
    "meta['pred'] = 'int'\n",
    "\n",
    "df_result = df_sample.map_partitions(predict, batch_size=8 , meta = meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bc17f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 743 ms, sys: 19.1 ms, total: 762 ms\n",
      "Wall time: 1min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_result_local = df_result.compute()\n",
    "df_result_local.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22827a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
